{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e150d50",
   "metadata": {},
   "source": [
    "\n",
    "# CRIM Intervals:  Melodic and Harmonic\n",
    "\n",
    "### Basic Goals\n",
    "\n",
    "- Examine Macro-level aspects of your Mass+Model corpus (with similarity Matrices and Cadence Maps)\n",
    "- Examine Micro-level aspects of your Mass+Model corpus (exploring particular ngrams, presentation types, and cadences made evident at the macro-level)\n",
    "- Draw some conclusions about the overall points of similarity and difference among some subset of your pieces\n",
    "\n",
    "### Tasks in Detail  \n",
    "\n",
    "### 1. Exploring Entry Melodies\n",
    "- 1.1 **Load the piece(s)** from your corpus\n",
    "\n",
    "#### Shared Entries (Macro Level)\n",
    "\n",
    "- 1.2 use the **piece.modelFinder** method to build a table summarizing the percentage of \"entries\" shared among the pieces.  These \"entries\" are soggetti (expressed as melodic ngrams) that begin after a rest or a section break.  They are thus the most likely soggetti to be remembered and the most likely to be used in important presentation types.\n",
    "- 1.3 The **heatmap of the modelFinder** results will show the relatedness clearly for your corpus.\n",
    "- 1.4 Which **mass movements** are most similar to the model?  To each other?\n",
    "\n",
    "#### Shared Modules (Macro Level)\n",
    "\n",
    "- 1.5 Now use **piece.moduleFinder** to build a table summarizing the percentage of \"contrapuntal modules\" shared in your corpus. These modules are also the ones that occur around the entries found in the previous step.\n",
    "- 1.6 Use the **heatmap of the moduleFinder** results to compare the relatedness in your corpus.\n",
    "- 1.7 How do these two calculations compare across the corpus at a macro level?  Which pieces seem to use similar melodies in the same ways?  In different ways?\n",
    "\n",
    "#### Shared Entries (Micro Level)\n",
    "- 1.8 Which **specific entry melodies** are shared by the to most similar pieces?  The list will give you an idea of which melodies are involved.\n",
    "- 1.9 Make a **HeatMap of the ngrams** in your pieces, and find your shared ngrams on them.\n",
    "- 1.10 Based on the visual blocks of the HeatMap (and the offsets that show when you hover on them):\n",
    "    - Where in your piece do these entries appear--at the outset, middle, near the end? \n",
    "    - Are they in roughly the same place in the two related movements/pieces?\n",
    "    - What Presentation Types do these shared entries seem to be involved in?  PEN?  ID?  Fuga? \n",
    "- 1.11 Now return to the **Presentation Type** method (**piece.presentationTypes**) and see what the CRIM intervals says about your pair of pieces and the partcular ngrams/entries you are focusing on.\n",
    "    - What types did it find?  Do you agree?  \n",
    "    - If you search for Hidden Types, does it find still others?\n",
    "    - Given that the composer of the Mass is definitely using soggetti from the Model, did they do the _same_ thing with that material as found in the model?  Or something different?  Do you they think they were being creative, or just going through the motions?\n",
    "    - If you listen to the piece, do any of the machine patterns make sense to you?\n",
    "    \n",
    "### 2. Shared Cadences\n",
    "\n",
    "- 2.1 About Cadence Methods\n",
    "\n",
    "#### Shared Cadences (Macro Level)\n",
    "- 2.2 Radar Plot the Cadences for Your Corpus (and compare)\n",
    "- 2.3 Summary of Cadences by Tone and Type across your Corpus\n",
    "--  For reference, this table might help you be more specific about the differences and simliarities among the pieces and the types of cadences they share.\n",
    "-- Consider each in turn and think about what makes your pieces **similar** or **different**.\n",
    "- 2.4. Your Commentary on the previous steps\n",
    "\n",
    "- 2.5  Tablular Summary of the Cadences in your Corpus\n",
    "- 2.6  Finding Last Lowest Tone of each Piece\n",
    "\n",
    "#### Shared Cadences (Micro Level)\n",
    "- 2.7  Plotting the Cadences in each piece as a Series\n",
    "- 2.8  Finding Substrings of similar Cadences\n",
    "- 2.9 ==> Your Commentary on the Cadence Tables and Charts\n",
    "    \n",
    "    \n",
    "### 3.  Overall Conclusions\n",
    "\n",
    "- How are your chosen pieces most related?  Most different?  Write a few sentences and provide some highlights from your analysis\n",
    "\n",
    "\n",
    "\n",
    "#### Read Documentation for Each Method\n",
    "- Read the documentation with this command `print(ImportedPiece.YourMethod.__doc__)`, where you will replace `'YourMethod'` with the name of the individual method, for example `print(ImportedPiece.melodic.__doc__)`\n",
    "\n",
    "\n",
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dd55e4",
   "metadata": {},
   "source": [
    "### A. Import Intervals and Other Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1ab1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crim_intervals\n",
    "from crim_intervals import * \n",
    "from crim_intervals import main_objs\n",
    "from os import listdir\n",
    "import os.path\n",
    "import crim_intervals.visualizations as viz\n",
    "import pandas as pd\n",
    "import re\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display\n",
    "import requests\n",
    "import os\n",
    "import glob\n",
    "import plotly.graph_objects as go\n",
    "from os import listdir\n",
    "import os.path\n",
    "\n",
    "# keep these functions\n",
    "\n",
    "def convertTuple(tup):\n",
    "    out = \"\"\n",
    "    if isinstance(tup, tuple):\n",
    "        out = ', '.join(tup)\n",
    "    return out\n",
    "\n",
    "def _offset_joiner(a):\n",
    "        b = ', '.join(map(str, a))\n",
    "        return b\n",
    "\n",
    "MYDIR = (\"saved_csv\")\n",
    "CHECK_FOLDER = os.path.isdir(MYDIR)\n",
    "\n",
    "# If folder doesn't exist, then create it.\n",
    "if not CHECK_FOLDER:\n",
    "    os.makedirs(MYDIR)\n",
    "    print(\"created folder : \", MYDIR)\n",
    "else:\n",
    "    print(MYDIR, \"folder already exists.\")\n",
    "    \n",
    "MUSDIR = (\"Music_Files\")\n",
    "CHECK_FOLDER = os.path.isdir(MUSDIR)\n",
    "\n",
    "# If folder doesn't exist, then create it.\n",
    "if not CHECK_FOLDER:\n",
    "    os.makedirs(MUSDIR)\n",
    "    print(\"created folder : \", MUSDIR)\n",
    "else:\n",
    "    print(MUSDIR, \"folder already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40786a23",
   "metadata": {},
   "source": [
    "## B. Importing a Piece\n",
    "\n",
    "* Choose ONE of the following!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bed9abd",
   "metadata": {},
   "source": [
    "### Importing Just One Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dcd69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your Model\n",
    "\n",
    "prefix = 'https://crimproject.org/mei/CRIM_Model_'\n",
    "\n",
    "model_ID = '0008' # <== put your ID number here!\n",
    "\n",
    "# join the strings and import piece\n",
    "url = prefix + model_ID + '.mei'\n",
    "piece = importScore(url)\n",
    "\n",
    "print(piece.metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf9297c",
   "metadata": {},
   "source": [
    "### Importing One Full Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5501c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Your Mass as a corpus\n",
    "corpus = []\n",
    "mass_id = \"0019\" # <== put your Mass number here!\n",
    "for l in range(1, 6):\n",
    "    mass = f'https://crimproject.org/mei/CRIM_Mass_{mass_id}_{l:01}.mei'\n",
    "    corpus.append(importScore(mass))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075a7a2d",
   "metadata": {},
   "source": [
    "### Import Model and Mass as a Combined Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5a6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Your Mass and Model as a combined Corpus:\n",
    "corpus_list = []\n",
    "prefix = 'https://crimproject.org/mei/CRIM_Model_'\n",
    "\n",
    "# select IDs for your Mass and Model\n",
    "model_id = \"0008\"  # <==  put your model number here!\n",
    "mass_id = \"0005\" # <== put your Mass number here!\n",
    "model = prefix + model_id + '.mei'\n",
    "corpus_list.append(model)\n",
    "for l in range(1, 6):\n",
    "    mass = f'https://crimproject.org/mei/CRIM_Mass_{mass_id}_{l:01}.mei'\n",
    "    corpus_list.append(mass)\n",
    "corpus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1753184",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = CorpusBase(corpus_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9786eda1",
   "metadata": {},
   "source": [
    "# Shared Entries (Macro Level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b592f4",
   "metadata": {},
   "source": [
    "### 1.1 Melodic Entries as Similarity Matrix\n",
    "\n",
    "* Use the **modelFinder** method to build a table summarizing the percentage of \"entries\" shared among the pieces. \n",
    "* These \"entries\" are soggetti (expressed as melodic ngrams) that begin after a rest or a section break.  They are thus the most likely soggetti to be remembered and the most likely to be used in important presentation types.\n",
    "* This method returns a \"driving distance table\" showing how likely each model was a source for each mass. This\n",
    "is represented by a score 0-1 where 0 means that this relationship was highly unlikely\n",
    "and 1 means that the the two are highly likely to be related in this way (or that a\n",
    "piece was compared to itself). Specifically, **the value is the percentage of each piece's\n",
    "thematic (i.e. recurring) melodies can be found as thematic melodies in all the other pieces in your corpus**. The\n",
    "specific number of times they appear in the model is not considered, provided that it is\n",
    "at least two.\n",
    "\n",
    "\n",
    "### How to Read the Results:\n",
    "\n",
    "* As you read across, you will see the percentage of melodies in the row value that come from the corresponding column value.  \n",
    "\n",
    "### Provide Your Commentary as indicated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff7c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = CorpusBase(corpus_list)\n",
    "similarity_matrix = corpus.modelFinder()\n",
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e683807",
   "metadata": {},
   "source": [
    "###  1.2 The Melodic Matrix as Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melodic matrix\n",
    "dataplot = sns.heatmap(similarity_matrix, cmap=\"YlGnBu\", annot=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3bdcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['https://crimproject.org/mei/CRIM_Model_0019.mei']\n",
    "mass_list = ['https://crimproject.org/mei/CRIM_Mass_0019_1.mei',\n",
    "             'https://crimproject.org/mei/CRIM_Mass_0019_2.mei',\n",
    "              'https://crimproject.org/mei/CRIM_Mass_0019_3.mei',\n",
    "                'https://crimproject.org/mei/CRIM_Mass_0019_4.mei',\n",
    "            'https://crimproject.org/mei/CRIM_Mass_0019_5.mei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a734dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_corp = CorpusBase(model_list)\n",
    "mass_corp = CorpusBase(mass_list)\n",
    "cross_plot = mod_corp.modelFinder(masses=mass_corp, models=mod_corp)\n",
    "cross_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdbe2fa",
   "metadata": {},
   "source": [
    "## ==> 1.4 Put your commentary on the shared entries matrix below\n",
    "\n",
    "* Which pieces in your set seem to be most closely related in terms of melodic entries?  Which ones are not?  Which movements of the Mass seem to share the most entries with each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf954d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f406b706",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ae638ae",
   "metadata": {},
   "source": [
    "# Shared Modules (Macro Level)\n",
    "\n",
    "### 1.5 Contrapuntal (Modular) Ngrams as Similarity Matrix\n",
    "\n",
    "* **Contrapuntal Modules** are 'ngrams' that represent the motion of a pair of voices.  The tool finds the patterns between every pair of voices, then filters these to correspond to the moments of the 'entries'.  So it tells us not only that there are shared melodies, but what is happening to the melodies in their contrapuntal context.\n",
    "* `moduleFinder`  method identifies all of the `modular ngrams` in each piece that **coincide with the melodic entries**.  These are the modules found in _all_ voices around the moment of the given melodic entry, so they will\n",
    "include both the entries and other soggetti, too.\n",
    "\n",
    "* Lists of unique modular ngrams are then compared across the corpus, resulting in a matrix of values.\n",
    "* This method returns a \"driving distance table\" showing how likely each model was a source for each mass. This\n",
    "is represented by a score 0-1 where 0 means that this relationship was highly unlikely\n",
    "and 1 means that the the two are highly likely to be related in this way (or that a\n",
    "piece was compared to itself). Specifically, **the value is the percentage of each piece's\n",
    "modular ngrams (the ones that occur at the moment of the entries) can be found in each of the other pieces in the corpus.**\n",
    "\n",
    "#### How to Read the Results:\n",
    "    - As you read across, you will see the percentage of modular ngrams in the row value that come from the corresponding column value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eda14c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = CorpusBase(corpus_list)\n",
    "module_matrix = corpus.moduleFinder()\n",
    "module_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506b980",
   "metadata": {},
   "source": [
    "### 1.6 Module Matrix as Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89225ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module matrix\n",
    "\n",
    "dataplot = sns.heatmap(module_matrix, cmap=\"YlGnBu\", annot=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e8e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix.compare(module_matrix).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b49dd9c",
   "metadata": {},
   "source": [
    "## ==>  Put your commentary on the shared modules matrix below\n",
    "\n",
    "* Which pieces in your set seem to be most closely related in terms of modular entries?  Which ones are not?  Which movements of the Mass seem to share the most modular with each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd8455f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e5770c8",
   "metadata": {},
   "source": [
    "\n",
    "# Shared Entries (Micro Level)\n",
    "\n",
    "#### Here we explore _where_ and _how_ the shared melodies are presented in each piece\n",
    "\n",
    "* Load a specific pair of closely related pieces from your corpus\n",
    "* Find exactly which melodic entries are shared\n",
    "* Find out *where* these melodies occur in each piece\n",
    "* Check the Fuga, PEN, and ID Presentation Types to see how the melodies are treated in each piece.  Pick one or two melodies (and Presentation Types) as examples to describe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a27710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the Model\n",
    "model = corpus_list[0] # <== the model will be score \"0\"\n",
    "model = importScore(model)\n",
    "\n",
    "# Specify the Mass Movement(s)\n",
    "mass_movement = corpus_list[1] # <== select the index number of your mass from the corpus.  \"1\" is the Kyrie, \"5\" is the Agnus\n",
    "mass_movement = importScore(mass_movement)\n",
    "print(model.metadata, mass_movement.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f679e4",
   "metadata": {},
   "source": [
    "### Get the Entries and Detailed Index for A Pair of Pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd2e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the model\n",
    "model_entries = model.entries(thematic=True, anywhere=True, n=4)\n",
    "# model_entries = model_entries.applymap(convertTuple)\n",
    "model_entries_det = model.detailIndex(model_entries, offset=True, progress=True)\n",
    "\n",
    "# for the mass movement\n",
    "mass_movement_entries = mass_movement.entries(thematic=True, anywhere=True, n=4)\n",
    "# mass_movement_entries = mass_movement_entries.applymap(convertTuple)\n",
    "mass_movement_entries_det = mass_movement.detailIndex(mass_movement_entries, offset=True, progress=True)\n",
    "\n",
    "# check the detailed view as needed for each\n",
    "# model_entries_det\n",
    "# mass_movement_entries_det"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158a8b0",
   "metadata": {},
   "source": [
    "### 1.8 Find the nGrams shared by your pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f77e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_entries = model.entries(thematic=True, anywhere=True, n=4)\n",
    "model_entries_stack = model_entries.stack()\n",
    "mass_movement_entries = mass_movement.entries(thematic=True, anywhere=True, n=4)\n",
    "mass_movement_entries_stack = mass_movement_entries.stack()\n",
    "shared_entries = list(set(mass_movement_entries_stack).intersection(model_entries_stack))\n",
    "shared_entries = shared_entries[1:]\n",
    "shared_entries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44b6918",
   "metadata": {},
   "source": [
    "### 1.9 Make a Heatmap of Shared Entries in Two Pieces\n",
    "\n",
    "* Let's look at **where** the shared melodies appear in each of your pieces.\n",
    "\n",
    "* Judging only from the visualization, where do the shared melodies appear, and how similar does the treatment of them seem to be?\n",
    "\n",
    "#### Note that you can also decide to compare one MASS movement with another MASS movement!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c0eab",
   "metadata": {},
   "source": [
    "### Model Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf3f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this for the Model Heatmap\n",
    "\n",
    "nr = model.notes(combineUnisons=True) \n",
    "mel = model.melodic(df=nr, kind='d', compound=True, unit=0, end=False)\n",
    "mel_ngrams = model.ngrams(df=mel, n=4)\n",
    "entry_ngrams = model.entries(df=mel, n=4)\n",
    "mel_ngrams_duration = model.durations(df=mel, n=4, mask_df=entry_ngrams)\n",
    "viz.plot_ngrams_heatmap(entry_ngrams, mel_ngrams_duration, selected_patterns=shared_entries, voices=[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e411a3a",
   "metadata": {},
   "source": [
    "### Mass Movement Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this for the Mass Movement Heatmap\n",
    "\n",
    "nr = mass_movement.notes(combineUnisons=True) \n",
    "mel = mass_movement.melodic(df=nr, kind='d', compound=True, unit=0, end=False)\n",
    "mel_ngrams = mass_movement.ngrams(df=mel, n=4)\n",
    "entry_ngrams = mass_movement.entries(df=mel, n=4)\n",
    "mel_ngrams_duration = mass_movement.durations(df=mel, n=4, mask_df=entry_ngrams)\n",
    "viz.plot_ngrams_heatmap(entry_ngrams, mel_ngrams_duration, selected_patterns=shared_entries, voices=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1ef3d5",
   "metadata": {},
   "source": [
    "## ==> 1.10 Your Commentary about the Heatmaps\n",
    "\n",
    "* Based on what you can see, **what do the composers seem to be doing with the shared melodies**?  \n",
    "* Do the composers use **certain melodies in the same approximate position**?  \n",
    "* Do they move through these melodies in the **same order or sequence** over the course of the piece?  \n",
    "* What **Presenation Types (Fuga, PEN, ID) seems to be involved**?  \n",
    "* Do any melodies seem particular worth comparing in terms of their treatment in the two pieces?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0500271b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52752e2c",
   "metadata": {},
   "source": [
    "#### Make the Short Lists of These Shared Ngrams and Their Offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a335cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the model\n",
    "model_short_list = model_entries_det[model_entries_det.isin(shared_entries)].dropna(how='all').stack()\n",
    "model_offsets_of_shared_entries = model_short_list.index.get_level_values(2)\n",
    "model_offsets_of_shared_entries = model_offsets_of_shared_entries.unique()\n",
    "\n",
    "# for the mass movement\n",
    "mass_movement_short_list = mass_movement_entries_det[mass_movement_entries_det.isin(shared_entries)].dropna(how='all').stack()\n",
    "mass_movement_offsets_of_shared_entries = mass_movement_short_list.index.get_level_values(2)\n",
    "mass_movement_offsets_of_shared_entries = mass_movement_offsets_of_shared_entries.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cf496b",
   "metadata": {},
   "source": [
    "### 1.11 Get Shared Entries as Presentation Types\n",
    "\n",
    "* Note that not all shared entries will be used as Fuga, ID, and PEN but for those that appear in a pair of pieces, it can be informative to compare **how** they are treated!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efd2c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we filter the PTypes to include ONLY those found in both the model and Mass movement\n",
    "\n",
    "# here for the model\n",
    "model_p_types = model.presentationTypes(limit_to_entries = True,\n",
    "                        body_flex = 0,\n",
    "                        head_flex = 1,\n",
    "                        include_hidden_types = False,\n",
    "                        combine_unisons = True,\n",
    "                       melodic_ngram_length = 4)\n",
    "\n",
    "model_shared_entry_ptypes = model_p_types[model_p_types.First_Offset.isin(model_offsets_of_shared_entries)]\n",
    "model_ptypes = model_shared_entry_ptypes.drop(columns=['Offsets', 'Number_Entries', 'Flexed_Entries', \"Parallel_Entries\", 'Parallel_Voice', 'Count_Non_Overlaps'])\n",
    "\n",
    "# here for the Mass movement\n",
    "\n",
    "\n",
    "mass_movement_p_types = mass_movement.presentationTypes(limit_to_entries = True,\n",
    "                        body_flex = 0,\n",
    "                        head_flex = 1,\n",
    "                        include_hidden_types = False,\n",
    "                        combine_unisons = True,\n",
    "                       melodic_ngram_length = 4)\n",
    "\n",
    "\n",
    "mass_movement_shared_entry_ptypes = mass_movement_p_types[mass_movement_p_types.First_Offset.isin(mass_movement_offsets_of_shared_entries)]\n",
    "mass_movement_ptypes = mass_movement_shared_entry_ptypes.drop(columns=['Offsets', 'Number_Entries', 'Flexed_Entries', \"Parallel_Entries\", 'Parallel_Voice', 'Count_Non_Overlaps'])\n",
    "combined_ptypes = pd.concat([model_ptypes, mass_movement_ptypes])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f09d671",
   "metadata": {},
   "source": [
    "### 1.11 (sorted!)  Now, Sort the Results so we see the Shared Melodies Together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0e8d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ptypes.sort_values('Soggetti')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d461536",
   "metadata": {},
   "source": [
    "## 1.11 ==> Your Commentary on the Presentation Type Comparison\n",
    "\n",
    "* Based on your estimation from the heatmap (above), what seems to be going on as the composer of the Mass quotes or transforms melodies from the Model?  \n",
    "* Pick **two or three shared melodies** and consider how the composer of the Mass and Model have treated them.  \n",
    "* What is the same or different about the **Time_Entry_Intervals** and  the **Melodic_Entry_Intervals**?  The overall predicted **Presentation_Type**?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cf88a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17a8b30c",
   "metadata": {},
   "source": [
    "# 2. Exploring Cadences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb5e9e",
   "metadata": {},
   "source": [
    "### 2.1 Comparing Cadences with Radar Plots and Tables (Macro Level)\n",
    "\n",
    "How do the cadential plans of your pieces compare?  Which pieces are similar or distinctive?\n",
    "\n",
    "In this section you will explore the 'tonal footprint' of your pieces with the Radar Plot tool.\n",
    "\n",
    "The tool counts and plots the number of cadences that end on a particular tone.  \n",
    "\n",
    "It also can provide a more detailed view that counts and plots the sub-types of cadences (some are strong, others weak).\n",
    "\n",
    "\n",
    "* Of course longer movements such as _Gloria_ and _Credo_ are likely to involve more cadences than short pieces.\n",
    "* But do the plots for the various pieces in your corpus resemble each other in overvall shape?\n",
    "* Are there any outliers?\n",
    "* What are the two or three main *tones* used in the cadences?\n",
    "\n",
    "Options:\n",
    "```\n",
    "corpus.compareCadenceRadarPlots(combinedType=False, displayAll=True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7767f8b4",
   "metadata": {},
   "source": [
    "### 2.2 Radar Plot the Cadences for Your Corpus\n",
    "\n",
    "You have various choices: \n",
    "\n",
    "* ```combinedType=False``` is relatively simple--just the **final tone** of each cadence in each piece\n",
    "* ```combinedType=False``` gives the **final tone and the special type** of the cadence (evaded or otherwise modified)\n",
    "* ```displayAll=True``` shows the cadences against a range of all possible cadences, with \"D\" at the top, then moving ahead by fifth (to A, E, etc)\n",
    "* ```displayAll=True``` shows only the cadence tones that appear in these pieces\n",
    "* It is also possible to limit the display to cadences involving on a specific number of voices:  ```sounding=3```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.compareCadenceRadarPlots(combinedType=False, displayAll=True, renderer='iframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e401f09",
   "metadata": {},
   "source": [
    "### 2.3  Summary of Cadences by Tone and Type across your Corpus\n",
    "\n",
    "* For reference, this table might help you be more specific about the differences and simliarities among the pieces and the types of cadences they share.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a31a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = ImportedPiece.cadences\n",
    "list_of_dfs = corpus.batch(func=func, kwargs={'keep_keys': True}, metadata=True)\n",
    "combined_df = pd.concat(list_of_dfs, ignore_index=False)\n",
    "col_list = ['Composer', 'Title', 'Measure', 'Beat', 'CadType', 'Tone', 'Progress']\n",
    "combined_df = combined_df[col_list]\n",
    "grouped_types = combined_df.groupby(['Tone', 'CadType', 'Composer', 'Title']).size().reset_index(name='counts')\n",
    "grouped_types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b45a16e",
   "metadata": {},
   "source": [
    "### Optional Radar for ONE piece at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d78f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece.cadenceRadarPlot(combinedType=True, displayAll=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61725764",
   "metadata": {},
   "source": [
    "## 2.4 ==> Your Commentary on the Radar Plots\n",
    "\n",
    "Consider each in turn and think about what makes your pieces **similar** or **different**:\n",
    "\n",
    "\n",
    "* Of course longer movements such as _Gloria_ and _Credo_ are likely to involve more cadences than short pieces.\n",
    "* But do the plots for the various pieces in your corpus **resemble each other in overvall shape**?\n",
    "* Are there any **outliers**?\n",
    "* What are the **two or three main *tones* used in the cadences**?\n",
    "* Which piece seems most varied (in terms of cadence tones and types?) Which is the most boring?\n",
    "* What new information does the **combined view** offer as we see the sub-types for each tone?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255d4820",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bae1304",
   "metadata": {},
   "source": [
    "### 2.5 Cadences as Table (in Order of their Apperance--Micro Level)\n",
    "\n",
    "* Here you can begin to think about the **order** of the cadences in your piece, rather than simply the counts in the aggregate as we find in the Radar Plot.\n",
    "\n",
    "* We should also consider the final lowest tone of the piece, which is a good indicator of the overall modality of the composition.\n",
    "\n",
    "* \"Progress\" is a measure from O to 1 of the relative position of this cadence in the piece.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db2f1a2",
   "metadata": {},
   "source": [
    "### 2.5b For a Single Piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dec3fa-7493-4e20-b873-91b53718730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you might need to make a copy of this cell in order to compare more than one piece easily!\n",
    "\n",
    "# change model to 'model' or 'mass_movement' below\n",
    "work = corpus_list[0] # <== the model will be score \"0\", the mass movements will be 1, 2, 3, 4, 5\n",
    "piece = importScore(work)\n",
    "cadences_df = piece.cadences()\n",
    "cadences_df.drop(columns=[\"CVFs\", \"LeadingTones\", \"Low\", \"RelLow\", \"RelTone\", \"TSig\", \"Sounding\", \"SinceLast\", \"ToNext\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a43a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you might need to make a copy of this cell in order to compare more than one piece easily!\n",
    "\n",
    "# change model to 'model' or 'mass_movement' below\n",
    "work = corpus_list[1] # <== the model will be score \"0\", the mass movements will be 1, 2, 3, 4, 5\n",
    "piece = importScore(work)\n",
    "cadences_df = piece.cadences()\n",
    "cadences_df.drop(columns=[\"CVFs\", \"LeadingTones\", \"Low\", \"RelLow\", \"RelTone\", \"TSig\", \"Sounding\", \"SinceLast\", \"ToNext\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b732b7",
   "metadata": {},
   "source": [
    "### 2.6 Find the Final Lowest Tones\n",
    "\n",
    "* The final lowest tone is a good indicator of the overall 'modality' of the piece.  It is not necessarily the main tone of the last cadence, since many of these pieces have a kind of 'coda' (or tail) to round things out.\n",
    "\n",
    "* But it is helpful to consider the final tone as you compare the other aspects of the cadences in each piece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60768cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lowest Tone of the Pieces:\n",
    "list_finals = []\n",
    "for work in corpus_list:\n",
    "    piece = importScore(work)\n",
    "    composer = piece.metadata.get('composer')\n",
    "    title = piece.metadata.get('title')\n",
    "    final = piece.final()\n",
    "    temp_dict = {'Composer': composer, 'Title': title, 'Final': final }\n",
    "    list_finals.append(temp_dict)\n",
    "corpus_finals = pd.DataFrame.from_dict(list_finals)\n",
    "corpus_finals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589db4e7",
   "metadata": {},
   "source": [
    "### 2.7 Charting the \"Flow\" of Cadences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698649c2",
   "metadata": {},
   "source": [
    "#### Show the progress of cadences for a corpus:\n",
    "\n",
    "The plot normalizes all cadences on a graph from beginning (0) to the end (1) of the piece.\n",
    "\n",
    "```piece.cadenceProgressPlot(includeType=True)``` shows details of cadence types.\n",
    "```piece.cadenceProgressPlot(includeType=False)``` shows only the tone of each cadence\n",
    "\n",
    "Full options for parameters:\n",
    "\n",
    "```corpus.compareCadenceProgressPlots(includeType=False, cadTone=None, cadType=None, includeLegend=True)```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e0eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.compareCadenceProgressPlots(includeType=False, cadTone=None, cadType=None, includeLegend=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bdd19b",
   "metadata": {},
   "source": [
    "#### Show the progress of cadences for a single piece:\n",
    "\n",
    "The plot normalizes all cadences on a graph from beginning (0) to the end (1) of the piece.\n",
    "\n",
    "```piece.cadenceProgressPlot(includeType=True)``` shows details of cadence types.\n",
    "```piece.cadenceProgressPlot(includeType=False)``` shows only the tone of each cadence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bacc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece.cadenceProgressPlot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d589a07",
   "metadata": {},
   "source": [
    "### 2.8 Shared Sequences of Cadences\n",
    "\n",
    "* Here we find all the 'sets' of three cadences in each piece and group them by set.\n",
    "\n",
    "* Which substrings are shared?  In which pieces?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410cf7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"NextCad\"] = combined_df.groupby('Title')[\"Tone\"].shift(-1)\n",
    "combined_df[\"PreviousCad\"] = combined_df.groupby('Title')[\"Tone\"].shift(1)\n",
    "combined_df = combined_df.fillna('')\n",
    "combined_df[\"CadenceSet\"] = combined_df[[\"PreviousCad\", \"Tone\", \"NextCad\"]].apply(\"_\".join, axis=1)\n",
    "groupedCadenceSets = combined_df.groupby(['CadenceSet', 'Composer', 'Title']).size().reset_index(name='counts')\n",
    "groupedCadenceSets = groupedCadenceSets[groupedCadenceSets['counts'] > 1]\n",
    "groupedCadenceSets.sort_values(['counts', 'CadenceSet'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276e10a",
   "metadata": {},
   "source": [
    "## 2.9 ==> Your Commentary on the Cadence Tables and Charts\n",
    "\n",
    "* Now that you have explored the cadences in *order* of their appearance, what additional similarities or differences do you notice about your pieces?\n",
    "\n",
    "* Are there any shared *sets* of cadences in your pieces?  How does the evidence of the sets compare with what you learned from the radar plots?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96314dd4-a644-4569-9fbe-274e78ee4eac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4766d4c2",
   "metadata": {},
   "source": [
    "# 3.  Overall Conclusions\n",
    "\n",
    "## ==> Your Commentary on the Cadence Tables and Charts\n",
    "\n",
    "- How are your chosen pieces most related?  Most different?  Write a few sentences and provide some highlights from your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778f15b5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8368d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Encoding Music)",
   "language": "python",
   "name": "encodingmusic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "339.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
